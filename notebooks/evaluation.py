# -*- coding: utf-8 -*-
"""evaluation.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1ZOkJNArw58GH09uNJVcBqnuIVzCLdXVR
"""

import pandas as pd
from scipy.sparse import csr_matrix
import random
import numpy as np
from sklearn.metrics.pairwise import cosine_similarity
from sklearn.metrics import mean_squared_error
import math
import pickle
import torch
import torch.nn as nn
import torch.optim as optim
import matplotlib.pyplot as plt

# at the top of evaluation.py
import pandas as pd
import os

BASE = os.path.dirname(__file__)           # notebooks/
CSV  = os.path.join(BASE, "data", "sparse_ratings_matrix.csv")

ratings_df = pd.read_csv(CSV, nrows=2517)
ratings_df = ratings_df.drop(ratings_df.columns[0], axis=1)
ratings_df = ratings_df.fillna(0)

ratings_sparse_mat = csr_matrix(ratings_df.values)
rows, cols = ratings_sparse_mat.nonzero()

## Convert the non-zero values into a 1D array
ratings = ratings_sparse_mat[rows, cols].A1

nonzero_data = [(int(r), int(c), int(v)) for r, c, v in zip(rows, cols, ratings)]
random.seed(42)
random.shuffle(nonzero_data)

dataset_length = len(nonzero_data)
val_percentage = 0.2

train_last_idx = int((1-val_percentage) * dataset_length)

train_data = nonzero_data[:train_last_idx]
val_data = nonzero_data[train_last_idx:]

train_data[0] ## this will have the format of (image_id, user_id, rating)

"""## Collaborative Filtering"""

## User-user similarity matrix
def compute_user_similarity(ratings_matrix):
    similarity = cosine_similarity(ratings_matrix)
    np.fill_diagonal(similarity, 0)
    return similarity

## Fills the sparse matrix with the predicted values
def predict_user_cf(ratings_matrix, similarity_matrix, k=10):
    n_users, n_items = ratings_matrix.shape
    ratings_array = ratings_matrix.toarray()
    predicted_ratings = np.zeros((n_users, n_items))

    for user_idx in range(n_users):
        # Get top-k similar users
        user_similarities = similarity_matrix[user_idx]
        top_k_users = np.argsort(user_similarities)[::-1][:k]

        for item_idx in range(n_items):
            if ratings_array[user_idx, item_idx] > 0: ## User has already rated this item
                predicted_ratings[user_idx, item_idx] = ratings_array[user_idx, item_idx]
                continue

            sim_users_ratings = ratings_array[top_k_users, item_idx]
            sim_users_sims = user_similarities[top_k_users]

            # Filter out users who haven't rated this item
            mask = sim_users_ratings > 0
            sim_users_ratings = sim_users_ratings[mask]
            sim_users_sims = sim_users_sims[mask]

            if len(sim_users_ratings) > 0:
                predicted_ratings[user_idx, item_idx] = np.sum(sim_users_ratings * sim_users_sims) / (np.sum(sim_users_sims) + 1e-10)

    return predicted_ratings

def precision_recall_at_k(predictions, k=10, threshold=7):
    n_users = predictions.shape[0]
    precision_scores = []
    recall_scores = []

    for user_idx in range(n_users):
        relevant_items = set()
        for image_id, user_id, rating in val_data:
            if user_id == user_idx and rating >= threshold:
                relevant_items.add(image_id)

        # Skip users with no relevant items
        if not relevant_items:
            continue

        # Get top-k recommendations
        user_ratings = predictions[user_idx]
        for image_id, user_id, rating in train_data:
            if user_id == user_idx:
                user_ratings[image_id] = -1
        top_k_items = np.argsort(user_ratings)[::-1][:k]
        top_k_items = set(top_k_items)

        # Calculate metrics
        n_rel_and_rec = len(relevant_items.intersection(top_k_items))

        precision = n_rel_and_rec / k if k != 0 else 0
        recall = n_rel_and_rec / len(relevant_items) if len(relevant_items) != 0 else 0

        precision_scores.append(precision)
        recall_scores.append(recall)

    avg_precision = np.mean(precision_scores) if precision_scores else 0
    avg_recall = np.mean(recall_scores) if recall_scores else 0

    return avg_precision, avg_recall

# Evaluate the model using train/val split
def evaluate_cf_model(train_data, val_data, n_users, n_items):
    ## Create training matrix
    train_matrix = np.zeros((n_items, n_users))
    for image_id, user_id, rating in train_data:
        train_matrix[image_id, user_id] = rating

    train_matrix_sparse = csr_matrix(train_matrix)

    ## Compute user similarity matrix and perform prediction
    similarity_matrix = compute_user_similarity(train_matrix_sparse.T)
    predictions = predict_user_cf(train_matrix_sparse.T, similarity_matrix, k=10) ## Fill the sparse matrix with the predicted values

    ## Recall and precision @ k
    precision, recall = precision_recall_at_k(predictions, k=10, threshold=7)

    ## Calculate the error
    val_predictions = []
    val_true_ratings = []

    for image_id, user_id, rating in val_data:
        predicted = predictions[user_id, image_id]
        if predicted > 0:
            val_predictions.append(predicted)
            val_true_ratings.append(rating)

    rmse = math.sqrt(mean_squared_error(val_true_ratings, val_predictions))
    mae = np.mean(np.abs(np.array(val_predictions) - np.array(val_true_ratings)))
    return rmse, mae, precision, recall

n_items, n_users = ratings_df.shape

rmse, mae, precision, recall = evaluate_cf_model(train_data, val_data, n_users, n_items)
print(f"RMSE: {rmse:.4f}")
print(f"MAE: {mae:.4f}")
print(f"Precision: {precision:.4f}")
print(f"Recall: {recall:.4f}")

"""## Two Towers"""

img_text_embeddings = pickle.load(open("dataset/img_text_embeddings.pkl", "rb"))

embeddings_df = img_text_embeddings[['image_key', 'text_embedding', 'image_embedding']]
embeddings_df['image_path'] = embeddings_df['image_key'].apply(lambda x: f"dataset/images/{x}.jpg")
embeddings_df = embeddings_df.drop(columns=['image_key'])
embeddings_df.head(2)

class TwoTowerModel(nn.Module):
    def __init__(self, embedding_dim=512):
        super(TwoTowerModel, self).__init__()
        self.user_tower = nn.Sequential(nn.Linear(embedding_dim, 256), nn.ReLU(),
                                        nn.Linear(256, 128))
        self.item_tower = nn.Sequential(nn.Linear(embedding_dim, 256), nn.ReLU(),
                                        nn.Linear(256, 128))

    def forward(self, user_emb, item_emb):
        user_repr = self.user_tower(user_emb)
        item_repr = self.item_tower(item_emb)
        return torch.cosine_similarity(user_repr, item_repr, dim=1)

def prepare_data(data, embeddings_df):
    text_embeddings = torch.tensor(embeddings_df['text_embedding'].tolist()).float()
    image_embeddings = torch.tensor(embeddings_df['image_embedding'].tolist()).float()

    user_embs = []
    item_embs = []
    ratings = []

    for image_id, user_id, rating in data:
        user_embs.append(text_embeddings[image_id])
        item_embs.append(image_embeddings[image_id])
        ratings.append(rating)

    return torch.stack(user_embs), torch.stack(item_embs), torch.tensor(ratings).float()

def prepare_two_tower_data(train_data, val_data, embeddings_df):
    """
    Prepare training and validation data for the two-tower model
    """
    train_user_embs, train_item_embs, train_ratings = prepare_data(train_data, embeddings_df)
    val_user_embs, val_item_embs, val_ratings = prepare_data(val_data, embeddings_df)

    return (train_user_embs, train_item_embs, train_ratings), (val_user_embs, val_item_embs, val_ratings)

def train_two_tower_model(model, train_data, val_data, num_epochs=10, batch_size=32):
    optimizer = optim.Adam(model.parameters(), lr=0.001)
    criterion = nn.MSELoss()

    train_user_embs, train_item_embs, train_ratings = train_data
    val_user_embs, val_item_embs, val_ratings = val_data

    train_losses = []
    val_losses = []

    for epoch in range(num_epochs):
        model.train()
        total_loss = 0

        # Training
        for i in range(0, len(train_ratings), batch_size):
            batch_user_embs = train_user_embs[i:i+batch_size]
            batch_item_embs = train_item_embs[i:i+batch_size]
            batch_ratings = train_ratings[i:i+batch_size]

            optimizer.zero_grad()
            predictions = model(batch_user_embs, batch_item_embs)
            loss = criterion(predictions, batch_ratings / 10.0)
            loss.backward()
            optimizer.step()

            total_loss += loss.item()

        avg_train_loss = total_loss / (len(train_ratings) / batch_size)
        train_losses.append(avg_train_loss)

        # Validation
        model.eval()
        with torch.no_grad():
            val_predictions = model(val_user_embs, val_item_embs)
            val_loss = criterion(val_predictions, val_ratings / 10.0)
            val_losses.append(val_loss.item())

        print(f'Epoch {epoch+1}/{num_epochs}:')
        print(f'Training Loss: {avg_train_loss:.4f}')
        print(f'Validation Loss: {val_loss.item():.4f}')
    return train_losses, val_losses

def evaluate_two_tower_model(model, val_data_tensors, val_data_original, embeddings_df):
    model.eval()
    val_user_embs, val_item_embs, val_ratings = val_data_tensors

    with torch.no_grad():
        predictions = model(val_user_embs, val_item_embs)
        predictions = predictions * 10.0

        # Calculate RMSE and MAE
        rmse = math.sqrt(mean_squared_error(val_ratings.numpy(), predictions.numpy()))
        mae = np.mean(np.abs(predictions.numpy() - val_ratings.numpy()))

        # Calculate Precision and Recall@k
        precision, recall = precision_recall_at_k_two_tower(
            model, embeddings_df, val_data_original, k=10, threshold=7)

    return rmse, mae, precision, recall

def precision_recall_at_k_two_tower(model, embeddings_df, val_data_original, k=10, threshold=7):
    model.eval()
    text_embeddings = torch.tensor(embeddings_df['text_embedding'].tolist()).float()
    image_embeddings = torch.tensor(embeddings_df['image_embedding'].tolist()).float()

    precision_scores = []
    recall_scores = []

    # Group validation data by user
    user_relevant_items = {}
    for image_id, user_id, rating in val_data_original:
        if rating >= threshold:
            if user_id not in user_relevant_items:
                user_relevant_items[user_id] = set()
            user_relevant_items[user_id].add(image_id)

    with torch.no_grad():
        for user_id, relevant_items in user_relevant_items.items():
            if not relevant_items:
                continue

            # Get predictions for all items for this user
            user_emb = text_embeddings[list(relevant_items)[0]]  # Use first relevant item's text embedding
            user_emb = user_emb.unsqueeze(0).repeat(len(image_embeddings), 1)

            predictions = model(user_emb, image_embeddings)

            # Get top k predictions
            top_k_items = torch.argsort(predictions, descending=True)[:k]
            recommended_items = set(top_k_items.numpy())

            # Calculate metrics
            n_rel_and_rec = len(relevant_items.intersection(recommended_items))
            precision = n_rel_and_rec / k
            recall = n_rel_and_rec / len(relevant_items)

            precision_scores.append(precision)
            recall_scores.append(recall)

    avg_precision = np.mean(precision_scores) if precision_scores else 0
    avg_recall = np.mean(recall_scores) if recall_scores else 0

    return avg_precision, avg_recall

EMBEDDING_DIMS = 512
model = TwoTowerModel(embedding_dim=EMBEDDING_DIMS)

train_data_tensors, val_data_tensors = prepare_two_tower_data(train_data, val_data, embeddings_df)
train_losses, val_losses = train_two_tower_model(model, train_data_tensors, val_data_tensors)
# after training:
torch.save(model.state_dict(), "data/two_tower.pth")


rmse, mae, precision, recall = evaluate_two_tower_model(model, val_data_tensors, val_data, embeddings_df)

print(f"Two-Tower Model Results:")
print(f"RMSE: {rmse:.4f}")
print(f"MAE: {mae:.4f}")
print(f"Precision@10: {precision:.4f}")
print(f"Recall@10: {recall:.4f}")

plt.figure(figsize=(10, 4))
plt.plot(train_losses, label='Training Loss')
plt.plot(val_losses, label='Validation Loss')
plt.title('Two-Tower Model Training')
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.legend()
plt.grid(True)
plt.show()

"""## Content Filtering"""



"""## Low Rank"""

